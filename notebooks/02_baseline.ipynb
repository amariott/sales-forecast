{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5212e38e",
   "metadata": {},
   "source": [
    "### Цель этого блокнота - построить базовую регрессионную модель для прогнозирования еженедельных продаж"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa8328",
   "metadata": {},
   "source": [
    "#### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89175ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
      "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
      "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
      "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
      "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
      "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
      "\n",
      "          CPI  Unemployment  \n",
      "0  211.096358         8.106  \n",
      "1  211.242170         8.106  \n",
      "2  211.289143         8.106  \n",
      "3  211.319643         8.106  \n",
      "4  211.350143         8.106  \n",
      "(6435, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/home/aroya/sales-forecast/data/raw/Walmart.csv\")\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143a53dc",
   "metadata": {},
   "source": [
    "Набор данных успешно загружен и содержит 6435 наблюдений с целевой переменной Weekly_Sales и множеством числовых и категориальных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e009c",
   "metadata": {},
   "source": [
    "#### Разделение на обучающую и тестовую выборки (по времени)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c745549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# предварительная подготовка данных\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'], dayfirst=True) # преобразуем колонку Date в datetime формат\n",
    "\n",
    "data['year'] = data['Date'].dt.year # из колонки Date извлечем год в отдельную колонку\n",
    "data['month'] = data['Date'].dt.month # из колонки Date извлечем месяц в отдельную колонку\n",
    "data['week_of_year'] = data['Date'].dt.isocalendar().week # из колонки Date извлечем неделю в отдельную колонку\n",
    "\n",
    "data = data.drop('Date', axis=1) # удалим уже ненужный Date\n",
    "\n",
    "x = data.drop(columns=['Weekly_Sales'])\n",
    "y = data['Weekly_Sales']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea851f",
   "metadata": {},
   "source": [
    "Для базовой обработки признаков было применено извлечение временных характеристик из столбца с датами. Поскольку данные имеют временную структуру, применяется разделение по времени, чтобы предотвратить утечку данных. Модель обучается на более ранних наблюдениях и оценивается на более поздних данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbca2a",
   "metadata": {},
   "source": [
    "#### Подготовка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beba0a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "стандартизация train\n",
      "      Store  Holiday_Flag  Temperature  Fuel_Price       CPI  Unemployment  \\\n",
      "0  0.845720     -0.272974     0.857397    0.668501 -1.076394      1.434379   \n",
      "1  1.459867     -0.272974     1.281702    1.361813 -1.080175      0.273484   \n",
      "2  0.538646     -0.272974     1.228259    0.616339  1.278441     -0.769537   \n",
      "3 -0.919953     -0.272974     1.016646   -1.411435  1.089416     -0.348868   \n",
      "4 -0.229038     -0.272974     0.750511    0.651114  1.095699     -0.382932   \n",
      "\n",
      "       year     month  week_of_year  \n",
      "0  0.052038  0.478983      0.365289  \n",
      "1  0.052038 -0.140332     -0.202304  \n",
      "2  1.303866  0.478983      0.649085  \n",
      "3 -1.199790 -0.140332     -0.273253  \n",
      "4  1.303866  0.478983      0.365289  \n",
      "\n",
      "стандартизация test\n",
      "      Store  Holiday_Flag  Temperature  Fuel_Price       CPI  Unemployment  \\\n",
      "0 -1.073490     -0.272974    -0.487315   -1.352754  1.090870     -0.850643   \n",
      "1 -1.303795     -0.272974    -0.050054   -1.446209  1.063590     -0.530545   \n",
      "2  1.613404     -0.272974    -2.023127   -0.826793 -1.113588     -0.413212   \n",
      "3 -0.382574     -0.272974    -1.977241    0.407694 -0.881629      0.046928   \n",
      "4  1.459867     -0.272974     0.790998   -0.596413 -1.148950      0.548703   \n",
      "\n",
      "       year     month  week_of_year  \n",
      "0 -1.199790 -1.069305     -0.982744  \n",
      "1 -1.199790  1.407956      1.287627  \n",
      "2  0.052038 -1.378963     -1.479388  \n",
      "3  1.303866 -1.688621     -1.621287  \n",
      "4 -1.199790  1.098298      1.074780  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdscaler = StandardScaler()\n",
    "\n",
    "feature_columns = data.columns.drop('Weekly_Sales').tolist()\n",
    "\n",
    "x_train = x_train[feature_columns]\n",
    "x_test = x_test[feature_columns]\n",
    "stdscaler.fit(x_train)\n",
    "\n",
    "train_std_scale = stdscaler.transform(x_train)\n",
    "test_std_scale = stdscaler.transform(x_test)\n",
    "\n",
    "print(f\"стандартизация train\\n{pd.DataFrame(train_std_scale, columns=feature_columns).head()}\\n\")\n",
    "print(f\"стандартизация test\\n{pd.DataFrame(test_std_scale, columns=feature_columns).head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8630165",
   "metadata": {},
   "source": [
    "Для сохранения простоты и интерпретируемости базовой модели использовались не сложные преобразования, а обычная стандартизация (хоть и Store - это категоривальное значение, для baseline нормальное такое преобразовывать). видим, что среднее ~ 0, а ско (std) ~ 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c6fea9",
   "metadata": {},
   "source": [
    "#### Обучение baseline-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe35600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          train          test\n",
      "0  9.278030e+05  1.143964e+06\n",
      "1  8.057080e+05  1.319489e+06\n",
      "2  7.885745e+05  8.264807e+05\n",
      "3  1.109155e+06  1.164666e+06\n",
      "4  1.011414e+06  8.538582e+05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_std_scale, y_train)\n",
    "y_linear_pred_train = model.predict(train_std_scale)\n",
    "y_linear_pred_test = model.predict(test_std_scale)\n",
    "\n",
    "print(pd.DataFrame({'train': y_linear_pred_train[:5],'test': y_linear_pred_test[:5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
